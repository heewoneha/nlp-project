{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30706bd9-2383-47ef-94dd-d4fe977d4fa1",
   "metadata": {},
   "source": [
    "## Pre-setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ab2a49-421e-46d2-bbee-83e257b82507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction, EarlyStoppingCallback \\\n",
    "    , AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from plugin import delete_folder, check_exists_cuda, load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a393807-9a10-4a23-811f-b01d2053500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'klue/roberta-large'\n",
    "\n",
    "sentiment_id_to_str = ['1', '-1', '0']  # pos: 0, neg: 1, neu: 2로 변환\n",
    "sentiment_str_to_id = {sentiment_id_to_str[i]: i for i in range(len(sentiment_id_to_str))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be64f827-4d17-4157-afef-825c6c1e3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class klue_Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Input: 정규표현식, 개수가 적은 속성 제거 등으로 전처리된 데이터셋\n",
    "    Ouput: 1차원 텐서(__getitem__) / 샘플의 수(__len__)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, label):\n",
    "        self.dataset = dataset # {'input_ids': ~, 'token_type_ids': ~, 'attention_mask': ~, 'entity_ids' : ~}\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "439fc4eb-45bc-4af9-ac98-2262cf2e75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    seed value를 고정하는 함수\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d323e38e-35e2-4c52-89bf-f29d57e62199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annotation_keys(jsonl_data):\n",
    "    \"\"\"\n",
    "    JSONL 데이터에서 annotation 키 목록을 추출하는 함수\n",
    "    \"\"\"\n",
    "    annotation_keys = []\n",
    "\n",
    "    for json_data in jsonl_data:\n",
    "        if \"annotation\" in json_data:\n",
    "            annotation_keys.extend([item[0] for item in json_data[\"annotation\"]])\n",
    "    \n",
    "    unique_annotation_keys = list(set(annotation_keys))\n",
    "\n",
    "    return unique_annotation_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56dce01-99d7-4622-b869-f7f73b03b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_datasets(data, main_category, original_aspects): # train, validation, test별로 들어옴 !\n",
    "    \"\"\"\n",
    "    속성 & 감성 관련 데이터 및 레이블을 정의하는 함수\n",
    "    \"\"\"\n",
    "    ASP_datas = [[] for i in range(len(original_aspects))]\n",
    "    ASP_labels = [[] for i in range(len(original_aspects))]\n",
    "\n",
    "    SEN_data = []\n",
    "    SEN_labels = []\n",
    "\n",
    "    for i, pair in enumerate(category_with_original_aspects):\n",
    "        for datas in data:\n",
    "            review = datas['raw_text']\n",
    "            annotations = datas['annotation']\n",
    "            check_point = False\n",
    "            \n",
    "            ASP_datas[i].append(review)\n",
    "            \n",
    "            for annotation in annotations:\n",
    "                entity_property = f'{main_category}#' + annotation[0]\n",
    "                sentiment = annotation[1]\n",
    "\n",
    "                if entity_property == pair:\n",
    "                    check_point = True\n",
    "                    \n",
    "            if check_point:\n",
    "                ASP_labels[i].append(1)\n",
    "                SEN_data.append(review + \" \" + pair)\n",
    "                SEN_labels.append(sentiment_str_to_id[sentiment])\n",
    "            \n",
    "            else:\n",
    "                ASP_labels[i].append(0)\n",
    "                \n",
    "        ASP_datas[i], ASP_labels[i] = shuffle(ASP_datas[i], ASP_labels[i], random_state = 42)\n",
    "        \n",
    "    SEN_data, SEN_labels = shuffle(SEN_data, SEN_labels, random_state = 42)\n",
    "    \n",
    "    return ASP_datas, ASP_labels, SEN_data, SEN_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e363f7e-e8c8-4f90-a75e-ce39f065f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_1d(val, Datas, labels, tokenizer, category_with_original_aspects=None): # train, validation, test별로 들어옴 !\n",
    "    \"\"\"\n",
    "    Class를 이용해 1차원 텐서로 변경하는 함수\n",
    "    \"\"\"\n",
    "    if val == 'aspect':\n",
    "        klue_sets = []\n",
    "\n",
    "        for i in range(len(category_with_original_aspects)):\n",
    "            tok_sentence = tokenizer(Datas[i], return_tensors=\"pt\", padding='max_length' \\\n",
    "                            , truncation=True, max_length=256, add_special_tokens=True)  \n",
    "            \n",
    "            klue_sets.append(klue_Dataset(tok_sentence, labels[i]))\n",
    "        \n",
    "        return klue_sets\n",
    "    \n",
    "    elif val == 'sentiment':\n",
    "        sen_tok_sentence = tokenizer(Datas, return_tensors=\"pt\", padding='max_length' \\\n",
    "                            , truncation=True,max_length=256, add_special_tokens=True)  \n",
    "        \n",
    "        SEN_klue_sets = klue_Dataset(sen_tok_sentence, labels)\n",
    "\n",
    "        return SEN_klue_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b060058-6fdc-4867-96bb-2e0d2f77988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(val, p: EvalPrediction):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      val이 aspect라면    average = 'binary',  (이진 분류)\n",
    "      val이 sentiment라면 average = 'weighted' (다중클래스 분류)\n",
    "    Output:\n",
    "      평가지표 점수\n",
    "    \"\"\"\n",
    "    if val == 'aspect':\n",
    "        average = 'binary'\n",
    "    elif val == 'sentiment':\n",
    "        average = 'weighted'\n",
    "    \n",
    "    labels = p.label_ids\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=average)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843ef46b-f986-4f02-bfbd-21b011a5fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test_evaluation(val, infers, infer_labels, category_with_original_aspects=None):\n",
    "    \"\"\"\n",
    "    속성/감성 모델의 테스트 평가지표 결과를 출력하는 함수\n",
    "    \"\"\"\n",
    "    if val == 'aspect':\n",
    "        length = len(category_with_original_aspects)\n",
    "        average = 'binary'\n",
    "    elif val == 'sentiment':\n",
    "        length = 1\n",
    "        average = 'weighted'\n",
    "    \n",
    "    for x in range(0, length):\n",
    "        print(x, \"th Test.....\")\n",
    "        labelss = []\n",
    "        for i in infer_labels[x]:\n",
    "            for j in i:\n",
    "                labelss.append(j)\n",
    "\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labelss, infers[x], average=average)\n",
    "        acc = accuracy_score(labelss, infers[x])\n",
    "\n",
    "        print(\"Accuracy: \", acc)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d87b46-89ae-48c6-aa0d-a4897a35ccf4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26745072-4edf-4504-8b35-18617eae60d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def aspect_trainer(main_category, category_with_original_aspects, train_aspect_klue_sets, validation_aspect_klue_sets):\n",
    "    for i in range(len(category_with_original_aspects)):\n",
    "        tmp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "    \n",
    "        output_dir = f'./{main_category}/model_aspect_' + str(i)\n",
    "    \n",
    "        pre_output_dir = f'./{main_category}/model_aspect_' + str(i-1)\n",
    "        delete_folder(pre_output_dir)\n",
    "    \n",
    "        training_ars = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=10,\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=4,\n",
    "            save_total_limit=5,\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate=1e-5,\n",
    "            weight_decay=0.01,\n",
    "            evaluation_strategy='epoch',\n",
    "            metric_for_best_model = 'f1',\n",
    "            load_best_model_at_end = True,\n",
    "        )\n",
    "    \n",
    "        trainer = Trainer(\n",
    "            model=tmp_model,\n",
    "            args=training_ars,\n",
    "            train_dataset=train_aspect_klue_sets[i],\n",
    "            eval_dataset=validation_aspect_klue_sets[i],\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics = lambda x: compute_metrics(val='aspect', p=x),\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "        )\n",
    "    \n",
    "        print(\"=============\")\n",
    "        print(i+1, \") Aspect Training ...\")\n",
    "        trainer.train()\n",
    "        tmp_model.save_pretrained(output_dir + \"_best\")\n",
    "    \n",
    "        # GPU Clean\n",
    "        with torch.no_grad(): tmp_model\n",
    "        del tmp_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # 마지막 폴더 지우기\n",
    "    final_output_dir = f'{main_category}/model_aspect_' + str(len(category_with_original_aspects)-1)\n",
    "    delete_folder(final_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cc65aa6-ca49-44c9-8f16-986343cad317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_evaluate_tests(main_category, category_with_original_aspects, test_aspect_klue_sets):\n",
    "    infers = [[] for i in range(len(category_with_original_aspects))]\n",
    "    infer_labels = [[] for i in range(len(category_with_original_aspects))]\n",
    "    \n",
    "    for i in range(len(category_with_original_aspects)):\n",
    "        print(\"=============\")\n",
    "        print(i+1, \") Aspect Test ...\")\n",
    "        BEST_MODEL_NAME = f'./{main_category}/model_aspect_' + str(i) + \"_best\"\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_NAME)\n",
    "        model.to(device)\n",
    "        dataloader = DataLoader(test_aspect_klue_sets[i], batch_size=4, shuffle=False)\n",
    "    \n",
    "        model.eval()\n",
    "        output_pred = []\n",
    "        output_prob = []\n",
    "        labels = []\n",
    "    \n",
    "        for z, data in enumerate(tqdm(dataloader)):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    input_ids=data['input_ids'].to(device),\n",
    "                    attention_mask=data['attention_mask'].to(device),\n",
    "                    token_type_ids=data['token_type_ids'].to(device)\n",
    "                )\n",
    "            logits = outputs[0]\n",
    "            prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            result = np.argmax(logits, axis=-1)\n",
    "            labels.append(data['label'].tolist())\n",
    "    \n",
    "            output_pred.append(result)\n",
    "            output_prob.append(prob)\n",
    "    \n",
    "        pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "        \n",
    "        infers[i].extend(pred_answer)\n",
    "        infer_labels[i].extend(labels)\n",
    "\n",
    "    return infers, infer_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d925b4-16a2-48b0-8f7f-4293ed3371ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_trainer(main_category, train_sentiment_klue_sets, validation_sentiment_klue_sets):\n",
    "    output_dir = f'./{main_category}/model_sentiment'\n",
    "    \n",
    "    tmp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "    tmp_model.resize_token_embeddings(tokenizer.vocab_size + num_added_toks)\n",
    "    \n",
    "    training_ars = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        save_total_limit=5,\n",
    "        save_strategy = \"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy='epoch',\n",
    "        metric_for_best_model = 'f1',\n",
    "        load_best_model_at_end = True,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=tmp_model,\n",
    "        args=training_ars,\n",
    "        train_dataset=train_sentiment_klue_sets,\n",
    "        eval_dataset=validation_sentiment_klue_sets,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics = lambda x: compute_metrics(val='sentiment', p=x),\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "    \n",
    "    print(\"=============\")\n",
    "    print(\"Sentiment Training ...\")\n",
    "    trainer.train()\n",
    "    tmp_model.save_pretrained(output_dir + \"_best\")\n",
    "\n",
    "    delete_folder(f'./{main_category}/model_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c5fa737-d3a5-4171-82ea-11b83e02423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_evaluate_tests(main_category, test_sentiment_klue_sets):\n",
    "    print(\"=============\")\n",
    "    print(\"Sentiment Test ...\")\n",
    "    BEST_MODEL_NAME = f'./{main_category}/model_sentiment_best'\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_NAME)\n",
    "    model.to(device)\n",
    "    dataloader = DataLoader(test_sentiment_klue_sets, batch_size=4, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    output_pred = []\n",
    "    output_prob = []\n",
    "    labels = []\n",
    "    \n",
    "    for z, data in enumerate(tqdm(dataloader)):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=data['input_ids'].to(device),\n",
    "                attention_mask=data['attention_mask'].to(device),\n",
    "                token_type_ids=data['token_type_ids'].to(device)\n",
    "            )\n",
    "        logits = outputs[0]\n",
    "        prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        result = np.argmax(logits, axis=-1)\n",
    "        labels.append(data['label'].tolist())\n",
    "    \n",
    "        output_pred.append(result)\n",
    "        output_prob.append(prob)\n",
    "    \n",
    "    pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "    \n",
    "    infers = [pred_answer]\n",
    "    infer_labels = [labels]\n",
    "\n",
    "    return infers, infer_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5075e2-1e05-4118-8d80-eb7ef71d1e79",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe35cd2-d618-4251-975f-3fa5b06295e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========cuda========\n",
      "Device: <class 'torch.cuda.device'>\n",
      "Count of using GPUs: 1\n",
      "Current cuda device: 0\n",
      "====================\n",
      "=================남성화장품====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not exists:  ./남성화장품/model_aspect_-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============\n",
      "1 ) Aspect Training ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1427' max='7130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1427/7130 04:19 < 17:18, 5.49 it/s, Epoch 2/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.209600</td>\n",
       "      <td>0.161502</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>0.962687</td>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.974811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='54' max='238' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 54/238 00:02 < 00:08, 20.44 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    check_exists_cuda(device)\n",
    "    \n",
    "    set_seed(42)\n",
    "    main_categories = [\n",
    "        #'스킨케어',\n",
    "        #'헤어_바디케어',\n",
    "        #'메이크업_뷰티소품',\n",
    "        '남성화장품'\n",
    "    ]\n",
    "    \n",
    "    for main_category in main_categories:\n",
    "        print(f\"================={main_category}====================\")\n",
    "        jsonl_file_path = f\"./preprocessed_data/{main_category}.jsonl\"\n",
    "        data = load_jsonl(jsonl_file_path)\n",
    "    \n",
    "        result = extract_annotation_keys(data)\n",
    "        original_aspects = sorted(result)\n",
    "        category_with_original_aspects = [f'{main_category}#{aspect}' for aspect in original_aspects]\n",
    "        \n",
    "        data_len = len(data)\n",
    "        \n",
    "        trains = data[:int(data_len*0.6)]\n",
    "        validations = data[int(data_len*0.6):int(data_len*0.8)]\n",
    "        tests = data[int(data_len*0.8):]\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        special_tokens_dict = {\n",
    "            'additional_special_tokens': category_with_original_aspects\n",
    "        }\n",
    "        \n",
    "        num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "        \n",
    "        train_ASP_datas, train_ASP_labels, train_SEN_data, train_SEN_labels = define_datasets(trains, main_category, original_aspects)\n",
    "        validation_ASP_datas, validation_ASP_labels, validation_SEN_data, validation_SEN_labels = define_datasets(validations, main_category, original_aspects)\n",
    "        test_ASP_datas, test_ASP_labels, test_SEN_data, test_SEN_labels = define_datasets(tests, main_category, original_aspects)\n",
    "    \n",
    "        # 1차원 변환, aspect는 리스트 반환하고 sentiment는 단일 반환\n",
    "        train_aspect_klue_sets = reshape_to_1d('aspect', train_ASP_datas, train_ASP_labels, tokenizer, category_with_original_aspects)\n",
    "        validation_aspect_klue_sets = reshape_to_1d('aspect', validation_ASP_datas, validation_ASP_labels, tokenizer, category_with_original_aspects)\n",
    "        test_aspect_klue_sets = reshape_to_1d('aspect', test_ASP_datas, test_ASP_labels, tokenizer, category_with_original_aspects)\n",
    "        \n",
    "        train_sentiment_klue_sets = reshape_to_1d('sentiment', train_SEN_data, train_SEN_labels, tokenizer)\n",
    "        validation_sentiment_klue_sets = reshape_to_1d('sentiment', validation_SEN_data, validation_SEN_labels, tokenizer)\n",
    "        test_sentiment_klue_sets = reshape_to_1d('sentiment', test_SEN_data, test_SEN_labels, tokenizer)\n",
    "\n",
    "        # Aspect model train & test\n",
    "        aspect_trainer(main_category, category_with_original_aspects, train_aspect_klue_sets, validation_aspect_klue_sets)\n",
    "        asp_infers, asp_infer_labels = aspect_evaluate_tests(main_category, category_with_original_aspects, test_aspect_klue_sets)\n",
    "        \n",
    "        # Aspect test scores 출력\n",
    "        show_test_evaluation('aspect', asp_infers, asp_infer_labels, category_with_original_aspects)\n",
    "\n",
    "        # Sentiment model train & test\n",
    "        sentiment_trainer(main_category, train_sentiment_klue_sets, validation_sentiment_klue_sets)\n",
    "        sen_infers, sen_infer_labels = sentiment_evaluate_tests(main_category, test_sentiment_klue_sets)\n",
    "        \n",
    "        # Sentiment test scores 출력\n",
    "        show_test_evaluation('sentiment', sen_infers, sen_infer_labels)\n",
    "\n",
    "        print(\"================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
