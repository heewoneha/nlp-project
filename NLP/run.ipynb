{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ab2a49-421e-46d2-bbee-83e257b82507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction\n",
    "from transformers import EarlyStoppingCallback\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from plugin import delete_folder, check_exists_cuda, load_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a393807-9a10-4a23-811f-b01d2053500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'klue/roberta-large'\n",
    "\n",
    "entity_property_pair = [ # 나중에 데이터로부터 불러와서 자동으로 만들어보자 !\n",
    "    '가격', '기능/효과', '디자인', '밀착력/접착력',\n",
    "    '발림성', '보습력/수분감/쿨링감', '사용감',\n",
    "    '색상', '성분', '용기', '용량', '유통기한',\n",
    "    '윤기/피부(톤)', '자극성', '제품구성', '제형',\n",
    "    '지속력/유지력', '편의성/활용성',\n",
    "    '품질', '피부타입', '향', '흡수력'\n",
    "]\n",
    "\n",
    "rep_entity_property_pair = [\n",
    "    '남성화장품#가격', '남성화장품#기능/효과', '남성화장품#디자인',\n",
    "    '남성화장품#밀착력/접착력', '남성화장품#발림성', '남성화장품#보습력/수분감/쿨링감',\n",
    "    '남성화장품#사용감', '남성화장품#색상', '남성화장품#성분', '남성화장품#용기',\n",
    "    '남성화장품#용량', '남성화장품#유통기한', '남성화장품#윤기/피부(톤)', '남성화장품#자극성',\n",
    "    '남성화장품#제품구성', '남성화장품#제형', '남성화장품#지속력/유지력', '남성화장품#편의성/활용성',\n",
    "    '남성화장품#품질', '남성화장품#피부타입', '남성화장품#향', '남성화장품#흡수력'\n",
    "]\n",
    "\n",
    "polarity_id_to_name = ['1', '-1', '0']  # pos: 0, neg: 1, neu: 2로 변환\n",
    "polarity_name_to_id = {polarity_id_to_name[i]: i for i in range(len(polarity_id_to_name))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be64f827-4d17-4157-afef-825c6c1e3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class klue_Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Input: 정규표현식, 개수가 적은 속성 제거 등으로 전처리된 데이터셋\n",
    "    Ouput: 1차원 텐서(__getitem__) / 샘플의 수(__len__)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, label):\n",
    "        self.dataset = dataset # {'input_ids': ~, 'token_type_ids': ~, 'attention_mask': ~, 'entity_ids' : ~}\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.dataset.items()}\n",
    "        item['label'] = torch.tensor(self.label[idx])\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "439fc4eb-45bc-4af9-ac98-2262cf2e75e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    seed value를 고정하는 함수\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f56dce01-99d7-4622-b869-f7f73b03b000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_datasets(data, main_category): # train, validation, test별로 들어옴 !\n",
    "    \"\"\"\n",
    "    속성 & 감성 관련 데이터 및 레이블을 정의하는 함수\n",
    "    \"\"\"\n",
    "    ACD_Datas = [[] for i in range(len(entity_property_pair))]\n",
    "    ACD_labels = [[] for i in range(len(entity_property_pair))]\n",
    "\n",
    "    POL_Datas = []\n",
    "    POL_labels = []\n",
    "\n",
    "    for idx, pair in enumerate(rep_entity_property_pair):\n",
    "        for datas in data:\n",
    "            sen = datas['raw_text']\n",
    "            annos = datas['annotation']\n",
    "            check_point = False\n",
    "            \n",
    "            ACD_Datas[idx].append(sen)\n",
    "            \n",
    "            for annotation in annos:\n",
    "                entity_property = f'{main_category}#' + annotation[0]  # raw_data의 annotation 추출\n",
    "                polarity = annotation[1]\n",
    "\n",
    "                if entity_property == pair:\n",
    "                    check_point = True\n",
    "                    \n",
    "            if check_point:\n",
    "                ACD_labels[idx].append(1)\n",
    "                POL_Datas.append(sen + \" \" + pair)\n",
    "                POL_labels.append(polarity_name_to_id[polarity])\n",
    "            \n",
    "            else:\n",
    "                ACD_labels[idx].append(0)\n",
    "                \n",
    "        ACD_Datas[idx], ACD_labels[idx] = shuffle(ACD_Datas[idx], ACD_labels[idx], random_state = 42)\n",
    "        \n",
    "    POL_Datas, POL_labels = shuffle(POL_Datas, POL_labels, random_state = 42)\n",
    "    \n",
    "    return ACD_Datas, ACD_labels, POL_Datas, POL_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e363f7e-e8c8-4f90-a75e-ce39f065f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_1d(val, Datas, labels, tokenizer): # train, validation, test별로 들어옴 !\n",
    "    \"\"\"\n",
    "    Class를 이용해 1차원 텐서로 변경하는 함수\n",
    "    \"\"\"\n",
    "    if val == 'aspect':\n",
    "        klue_sets = []\n",
    "\n",
    "        for i in range(len(rep_entity_property_pair)):\n",
    "            tok_sen = tokenizer(Datas[i], return_tensors=\"pt\", padding='max_length',\n",
    "                                truncation=True, max_length=256, add_special_tokens=True)  \n",
    "            \n",
    "            klue_sets.append(klue_Dataset(tok_sen, labels[i]))\n",
    "        \n",
    "        return klue_sets\n",
    "    \n",
    "    elif val == 'sentiment':\n",
    "        pol_tok_sen = tokenizer(Datas, return_tensors=\"pt\", padding='max_length',\n",
    "                            truncation=True,max_length=256, add_special_tokens=True)  \n",
    "        \n",
    "        POL_klue_sets = klue_Dataset(pol_tok_sen, labels)\n",
    "\n",
    "        return POL_klue_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b060058-6fdc-4867-96bb-2e0d2f77988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(val, p: EvalPrediction):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      val이 aspect라면    average = 'binary',  (이진 분류)\n",
    "      val이 sentiment라면 average = 'weighted' (다중클래스 분류)\n",
    "    Output:\n",
    "      평가지표 점수\n",
    "    \"\"\"\n",
    "    if val == 'aspect':\n",
    "        average = 'binary'\n",
    "    elif val == 'sentiment':\n",
    "        average = 'weighted'\n",
    "    \n",
    "    labels = p.label_ids\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=average)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {'accuracy': acc, 'f1': f1, 'precision': precision, 'recall': recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "843ef46b-f986-4f02-bfbd-21b011a5fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_test_evaluation(val, infer_labels, infers):\n",
    "    if val == 'aspect':\n",
    "        length = len(rep_entity_property_pair)\n",
    "        average = 'binary'\n",
    "    elif val == 'sentiment':\n",
    "        length = 1\n",
    "        average = 'weighted'\n",
    "    \n",
    "    for x in range(0, length):\n",
    "        print(x, \"th Test.....\")\n",
    "        labelss = []\n",
    "        for i in infer_labels[x]:\n",
    "            for j in i:\n",
    "                labelss.append(j)\n",
    "\n",
    "        print(len(labelss), len(infers[x]))\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labelss, infers[x], average=average)\n",
    "        acc = accuracy_score(labelss, infers[x])\n",
    "\n",
    "        print(\"Accuracy: \", acc)\n",
    "        print(\"Precision:\", precision)\n",
    "        print(\"Recall:\", recall)\n",
    "        print(\"F1-score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5075e2-1e05-4118-8d80-eb7ef71d1e79",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe35cd2-d618-4251-975f-3fa5b06295e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========cuda========\n",
      "Device: <class 'torch.cuda.device'>\n",
      "Count of using GPUs: 1\n",
      "Current cuda device: 0\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "check_exists_cuda(device)\n",
    "\n",
    "set_seed(42)\n",
    "main_categories = ['남성화장품']\n",
    "\n",
    "# test\n",
    "main_category = main_categories[0]\n",
    "data = load_jsonl(f'./preprocessed_data/{main_category}.jsonl')\n",
    "\n",
    "trains = data[:2823]\n",
    "validations = data[2823:3763]\n",
    "tests = data[3763:]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "special_tokens_dict = {\n",
    "    'additional_special_tokens': rep_entity_property_pair\n",
    "}\n",
    "\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "train_ACD_Datas, train_ACD_labels, train_POL_Datas, train_POL_labels = define_datasets(trains, main_category)\n",
    "validation_ACD_Datas, validation_ACD_labels, validation_POL_Datas, validation_POL_labels = define_datasets(validations, main_category)\n",
    "test_ACD_Datas, test_ACD_labels, test_POL_Datas, test_POL_labels = define_datasets(tests, main_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "612d0c66-ba4e-4794-97ea-2e4ead4630c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차원 변환, aspect는 리스트 반환하고 sentiment는 단일 반환\n",
    "train_aspect_klue_sets = reshape_to_1d('aspect', train_ACD_Datas, train_ACD_labels, tokenizer)\n",
    "validation_aspect_klue_sets = reshape_to_1d('aspect', validation_ACD_Datas, validation_ACD_labels, tokenizer)\n",
    "test_aspect_klue_sets = reshape_to_1d('aspect', test_ACD_Datas, test_ACD_labels, tokenizer)\n",
    "\n",
    "train_sentiment_klue_sets = reshape_to_1d('sentiment', train_POL_Datas, train_POL_labels, tokenizer)\n",
    "validation_sentiment_klue_sets = reshape_to_1d('sentiment', validation_POL_Datas, validation_POL_labels, tokenizer)\n",
    "test_sentiment_klue_sets = reshape_to_1d('sentiment', test_POL_Datas, test_POL_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26745072-4edf-4504-8b35-18617eae60d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not exists:  ./ABSA-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th Trarining.... ========================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='7060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  92/7060 00:15 < 19:50, 5.86 it/s, Epoch 0.13/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### aspect trainer\n",
    "for i in range(len(rep_entity_property_pair)):\n",
    "    tmp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "\n",
    "    odir = './ABSA' + str(i)\n",
    "\n",
    "    pre_odir = './ABSA' + str(i-1)\n",
    "    delete_folder(pre_odir)\n",
    "\n",
    "    training_ars = TrainingArguments(\n",
    "        output_dir=odir,\n",
    "        num_train_epochs=10,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        save_total_limit=5,\n",
    "        save_strategy = \"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy='epoch',\n",
    "        metric_for_best_model = 'f1',\n",
    "        load_best_model_at_end = True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=tmp_model,\n",
    "        args=training_ars,\n",
    "        train_dataset=train_aspect_klue_sets[i],\n",
    "        eval_dataset=validation_aspect_klue_sets[i],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics = lambda x: compute_metrics(val='aspect', p=x),\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    print(i, \"th Trarining.... ========================================\")\n",
    "    trainer.train()\n",
    "    tmp_model.save_pretrained(odir + \"_best\")\n",
    "\n",
    "    # GPU Clean\n",
    "    with torch.no_grad(): tmp_model\n",
    "    del tmp_model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9943e87c-be1b-44f9-b5e0-c17a6ebd382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_odir = 'ABSA' + str(len(rep_entity_property_pair)-1)\n",
    "delete_folder(final_odir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc65aa6-ca49-44c9-8f16-986343cad317",
   "metadata": {},
   "outputs": [],
   "source": [
    "### aspect evaluate tests\n",
    "\n",
    "infers = [[] for i in range(len(rep_entity_property_pair))]\n",
    "infer_labels = [[] for i in range(len(rep_entity_property_pair))]\n",
    "\n",
    "for i in range(len(rep_entity_property_pair)):\n",
    "    print(i, \"th Test.... ========================================\")\n",
    "    BEST_MODEL_NAME = './ABSA' + str(i) + \"_best\"\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_NAME)\n",
    "    model.to(device)\n",
    "    dataloader = DataLoader(test_aspect_klue_sets[i], batch_size=4, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    output_pred = []\n",
    "    output_prob = []\n",
    "    labels = []\n",
    "\n",
    "    for z, data in enumerate(tqdm(dataloader)):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=data['input_ids'].to(device),\n",
    "                attention_mask=data['attention_mask'].to(device),\n",
    "                token_type_ids=data['token_type_ids'].to(device)\n",
    "            )\n",
    "        logits = outputs[0]\n",
    "        prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        result = np.argmax(logits, axis=-1)\n",
    "        labels.append(data['label'].tolist())\n",
    "\n",
    "        output_pred.append(result)\n",
    "        output_prob.append(prob)\n",
    "\n",
    "    pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "    \n",
    "    infers[i].extend(pred_answer)\n",
    "    infer_labels[i].extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd58616-b2bc-462d-851e-ffad2da47ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print aspect test scores\n",
    "show_test_evaluation('aspect', infer_labels, infers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d925b4-16a2-48b0-8f7f-4293ed3371ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentiment trainer\n",
    "\n",
    "odir = './ABSA_pol'\n",
    "\n",
    "tmp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "tmp_model.resize_token_embeddings(tokenizer.vocab_size + num_added_toks)\n",
    "\n",
    "training_ars = TrainingArguments(\n",
    "    output_dir=odir,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    save_total_limit=5,\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy='epoch',\n",
    "    metric_for_best_model = 'f1',\n",
    "    load_best_model_at_end = True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=tmp_model,\n",
    "    args=training_ars,\n",
    "    train_dataset=train_sentiment_klue_sets,\n",
    "    eval_dataset=validation_sentiment_klue_sets,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics = lambda x: compute_metrics(val='sentiment', p=x),\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")\n",
    "\n",
    "print(\"0th Trarining.... ========================================\")\n",
    "trainer.train()\n",
    "tmp_model.save_pretrained(odir + \"_best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996395d9-bc99-42ae-9c20-ebb28d9ce556",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_folder('./ABSA_pol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5fa737-d3a5-4171-82ea-11b83e02423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentiment evaluate tests\n",
    "\n",
    "print(0, \"th Test.... ========================================\")\n",
    "BEST_MODEL_NAME = './ABSA_pol_best'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_NAME)\n",
    "model.to(device)\n",
    "dataloader = DataLoader(test_sentiment_klue_sets, batch_size=4, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "output_pred = []\n",
    "output_prob = []\n",
    "labels = []\n",
    "\n",
    "for z, data in enumerate(tqdm(dataloader)):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=data['input_ids'].to(device),\n",
    "            attention_mask=data['attention_mask'].to(device),\n",
    "            token_type_ids=data['token_type_ids'].to(device)\n",
    "        )\n",
    "    logits = outputs[0]\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    result = np.argmax(logits, axis=-1)\n",
    "    labels.append(data['label'].tolist())\n",
    "\n",
    "    output_pred.append(result)\n",
    "    output_prob.append(prob)\n",
    "\n",
    "pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "\n",
    "infers = [pred_answer]\n",
    "infer_labels = [labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc465f-0056-4ee5-a50d-6d2685f7de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print sentiment test scores\n",
    "show_test_evaluation('aspect', infer_labels, infers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
