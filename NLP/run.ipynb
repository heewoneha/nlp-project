{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30706bd9-2383-47ef-94dd-d4fe977d4fa1",
   "metadata": {},
   "source": [
    "## Pre-setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ab2a49-421e-46d2-bbee-83e257b82507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback \\\n",
    "    , AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from etc_plugin import delete_folder, check_exists_cuda, load_jsonl\n",
    "from model_plugin import set_seed, extract_annotation_keys, define_datasets \\\n",
    "    , reshape_to_1d, compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a393807-9a10-4a23-811f-b01d2053500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'klue/roberta-base'\n",
    "TR_VL_SPLIT = 0.6\n",
    "VL_TS_SPLIT = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d87b46-89ae-48c6-aa0d-a4897a35ccf4",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26745072-4edf-4504-8b35-18617eae60d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def aspect_trainer(tokenizer, main_category, train_aspect_klue_sets, validation_aspect_klue_sets):\n",
    "    length = len(train_aspect_klue_sets)\n",
    "\n",
    "    for i in range(length):\n",
    "        tmp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "    \n",
    "        output_dir = f'./{main_category}/model_aspect_' + str(i)\n",
    "    \n",
    "        pre_output_dir = f'./{main_category}/model_aspect_' + str(i-1)\n",
    "        delete_folder(pre_output_dir)\n",
    "    \n",
    "        training_ars = TrainingArguments(\n",
    "            output_dir=output_dir,\n",
    "            num_train_epochs=5,\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=4,\n",
    "            save_total_limit=5,\n",
    "            save_strategy = \"epoch\",\n",
    "            learning_rate=1e-5,\n",
    "            weight_decay=0.01,\n",
    "            evaluation_strategy='epoch',\n",
    "            metric_for_best_model = 'f1',\n",
    "            load_best_model_at_end = True,\n",
    "        )\n",
    "    \n",
    "        trainer = Trainer(\n",
    "            model=tmp_model,\n",
    "            args=training_ars,\n",
    "            train_dataset=train_aspect_klue_sets[i],\n",
    "            eval_dataset=validation_aspect_klue_sets[i],\n",
    "            tokenizer=tokenizer,\n",
    "            compute_metrics = lambda x: compute_metrics(val='aspect', p=x),\n",
    "            callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "        )\n",
    "    \n",
    "        print(\"=============\")\n",
    "        print(i+1, \") Aspect Training ...\")\n",
    "        trainer.train()\n",
    "        tmp_model.save_pretrained(output_dir + \"_best\")\n",
    "    \n",
    "        # GPU Clean\n",
    "        with torch.no_grad(): tmp_model\n",
    "        del tmp_model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # 마지막 폴더 지우기\n",
    "    final_output_dir = f'{main_category}/model_aspect_' + str(length-1)\n",
    "    delete_folder(final_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d925b4-16a2-48b0-8f7f-4293ed3371ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_trainer(tokenizer, num_added_toks, main_category, train_sentiment_klue_sets, validation_sentiment_klue_sets):\n",
    "    output_dir = f'./{main_category}/model_sentiment'\n",
    "    \n",
    "    tmp_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "    tmp_model.resize_token_embeddings(tokenizer.vocab_size + num_added_toks)\n",
    "    \n",
    "    training_ars = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        save_total_limit=5,\n",
    "        save_strategy = \"epoch\",\n",
    "        learning_rate=1e-5,\n",
    "        weight_decay=0.01,\n",
    "        evaluation_strategy='epoch',\n",
    "        metric_for_best_model = 'f1',\n",
    "        load_best_model_at_end = True,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=tmp_model,\n",
    "        args=training_ars,\n",
    "        train_dataset=train_sentiment_klue_sets,\n",
    "        eval_dataset=validation_sentiment_klue_sets,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics = lambda x: compute_metrics(val='sentiment', p=x),\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "    \n",
    "    print(\"=============\")\n",
    "    print(\"Sentiment Training ...\")\n",
    "    trainer.train()\n",
    "    tmp_model.save_pretrained(output_dir + \"_best\")\n",
    "\n",
    "    delete_folder(f'./{main_category}/model_sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5075e2-1e05-4118-8d80-eb7ef71d1e79",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe35cd2-d618-4251-975f-3fa5b06295e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    check_exists_cuda(device)\n",
    "    \n",
    "    set_seed()\n",
    "    main_categories = [\n",
    "        '스킨케어',\n",
    "        '헤어_바디케어',\n",
    "        '메이크업_뷰티소품',\n",
    "        '남성화장품'\n",
    "    ]\n",
    "    \n",
    "    for main_category in main_categories:\n",
    "        print(f\"================={main_category}====================\")\n",
    "        jsonl_file_path = f\"./preprocessed_data/{main_category}.jsonl\"\n",
    "        data = load_jsonl(jsonl_file_path)\n",
    "    \n",
    "        result = extract_annotation_keys(data)\n",
    "        original_aspects = sorted(result)\n",
    "        category_with_original_aspects = [f'{main_category}#{aspect}' for aspect in original_aspects]\n",
    "        \n",
    "        data_len = len(data)\n",
    "        \n",
    "        trains = data[:int(data_len*TR_VL_SPLIT)]\n",
    "        validations = data[int(data_len*TR_VL_SPLIT):int(data_len*VL_TS_SPLIT)]\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        special_tokens_dict = {\n",
    "            'additional_special_tokens': category_with_original_aspects\n",
    "        }\n",
    "        \n",
    "        num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "        \n",
    "        train_ASP_datas, train_ASP_labels, train_SEN_data, train_SEN_labels = define_datasets(trains, main_category, category_with_original_aspects)\n",
    "        validation_ASP_datas, validation_ASP_labels, validation_SEN_data, validation_SEN_labels = define_datasets(validations, main_category, category_with_original_aspects)\n",
    "        \n",
    "        # 1차원 변환, aspect는 리스트 반환하고 sentiment는 단일 반환\n",
    "        train_aspect_klue_sets = reshape_to_1d('aspect', train_ASP_datas, train_ASP_labels, tokenizer)\n",
    "        validation_aspect_klue_sets = reshape_to_1d('aspect', validation_ASP_datas, validation_ASP_labels, tokenizer)\n",
    "        \n",
    "        train_sentiment_klue_sets = reshape_to_1d('sentiment', train_SEN_data, train_SEN_labels, tokenizer)\n",
    "        validation_sentiment_klue_sets = reshape_to_1d('sentiment', validation_SEN_data, validation_SEN_labels, tokenizer)\n",
    "        \n",
    "        # Aspect model train & test\n",
    "        aspect_trainer(tokenizer, main_category, train_aspect_klue_sets, validation_aspect_klue_sets)\n",
    "        \n",
    "        # Sentiment model train & test\n",
    "        sentiment_trainer(tokenizer, num_added_toks, main_category, train_sentiment_klue_sets, validation_sentiment_klue_sets)\n",
    "        \n",
    "        print(\"================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
