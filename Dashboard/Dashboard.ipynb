{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c830a8c-7238-431b-ac99-cc24a6509fc3",
   "metadata": {},
   "source": [
    "## Predict Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7b698f2-51bd-4451-9178-472d0174ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "\n",
    "from NLP.etc_plugin import check_exists_cuda\n",
    "from NLP.model_plugin import set_seed, prepare_data_and_categories, \\\n",
    "    define_datasets, reshape_to_1d, show_test_evaluation, MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5110fa10-082d-4ef4-8c1a-ef130d3ca6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspect_evaluate_tests(device, main_category, test_aspect_klue_sets):\n",
    "    length = len(test_aspect_klue_sets)\n",
    "\n",
    "    infers = [[] for i in range(length)]\n",
    "    infer_labels = [[] for i in range(length)]\n",
    "    \n",
    "    for i in range(length):\n",
    "        print(\"=============\")\n",
    "        print(i+1, \") Aspect Test ...\")\n",
    "        BEST_MODEL_NAME = f'./NLP/{main_category}/model_aspect_' + str(i) + \"_best\"\n",
    "        \n",
    "        best_model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_NAME)\n",
    "        best_model.to(device) # model을 GPU로 이동\n",
    "        \n",
    "        dataloader = DataLoader(test_aspect_klue_sets[i], batch_size=4, shuffle=False)\n",
    "    \n",
    "        best_model.eval()\n",
    "        output_pred = []\n",
    "        output_prob = []\n",
    "        labels = []\n",
    "    \n",
    "        for data in tqdm(dataloader):\n",
    "            with torch.no_grad():\n",
    "                outputs = best_model(\n",
    "                    input_ids=data['input_ids'].to(device), # data를 GPU로 이동\n",
    "                    attention_mask=data['attention_mask'].to(device),\n",
    "                    token_type_ids=data['token_type_ids'].to(device)\n",
    "                )\n",
    "            logits = outputs[0]\n",
    "            prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            result = np.argmax(logits, axis=-1)\n",
    "            labels.append(data['label'].tolist())\n",
    "    \n",
    "            output_pred.append(result)\n",
    "            output_prob.append(prob)\n",
    "    \n",
    "        pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "        \n",
    "        infers[i].extend(pred_answer)\n",
    "        infer_labels[i].extend(labels)\n",
    "\n",
    "    return infers, infer_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98fe2cc-2e55-465a-bf6a-2c4565374243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_evaluate_tests(device, main_category, test_sentiment_klue_sets):\n",
    "    print(\"=============\")\n",
    "    print(\"Sentiment Test ...\")\n",
    "    BEST_MODEL_NAME = f'./NLP/{main_category}/model_sentiment_best'\n",
    "    \n",
    "    best_model = AutoModelForSequenceClassification.from_pretrained(BEST_MODEL_NAME)\n",
    "    best_model.to(device)\n",
    "    \n",
    "    dataloader = DataLoader(test_sentiment_klue_sets, batch_size=4, shuffle=False)\n",
    "    \n",
    "    best_model.eval()\n",
    "    output_pred = []\n",
    "    output_prob = []\n",
    "    labels = []\n",
    "    \n",
    "    for data in tqdm(dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = best_model(\n",
    "                input_ids=data['input_ids'].to(device),\n",
    "                attention_mask=data['attention_mask'].to(device),\n",
    "                token_type_ids=data['token_type_ids'].to(device)\n",
    "            )\n",
    "        logits = outputs[0]\n",
    "        prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        result = np.argmax(logits, axis=-1)\n",
    "        labels.append(data['label'].tolist())\n",
    "    \n",
    "        output_pred.append(result)\n",
    "        output_prob.append(prob)\n",
    "    \n",
    "    pred_answer, output_prob = np.concatenate(output_pred).tolist(), np.concatenate(output_prob, axis=0).tolist()\n",
    "    \n",
    "    infers = [pred_answer]\n",
    "    infer_labels = [labels]\n",
    "\n",
    "    return infers, infer_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f16b4f4-a57a-4bd5-9171-d977617205b3",
   "metadata": {},
   "source": [
    "## Save Prediction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56d0f46d-9e42-4996-8d9d-587de34c6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction_results(main_category, category_with_original_aspects \\\n",
    "                            , test_ASP_datas, test_ASP_labels, asp_infers \\\n",
    "                            , test_SEN_data, test_SEN_labels, sen_infers):\n",
    "    \"\"\"\n",
    "    BEST 모델에 test 데이터셋을 넣어 예측한 값, 정답 및 리뷰 원문을 csv로 저장하는 함수\n",
    "    \"\"\"\n",
    "    ### 속성(Aspect) ###\n",
    "    asp_file_path = f'./NLP/{main_category}/'\n",
    "\n",
    "    asp_data_list = [\n",
    "        ['sentence', 'prediction', 'correct'], # Column Title\n",
    "    ]\n",
    "\n",
    "    for i in range(0, len(test_ASP_datas[0])):\n",
    "        prediction_aspects = []\n",
    "        correct_aspects = []\n",
    "        for j in range(0, len(category_with_original_aspects)):\n",
    "            if asp_infers[j][i]:\n",
    "                prediction_aspects.append(category_with_original_aspects[j])\n",
    "            if test_ASP_labels[j][i]:\n",
    "                correct_aspects.append(category_with_original_aspects[j])\n",
    "        asp_data_list.append([test_ASP_datas[0][i], prediction_aspects, correct_aspects])\n",
    "\n",
    "    # Unnesting Prediction\n",
    "    transformed_asp_prediction_data_list = [\n",
    "        ['id', 'sentence', 'prediction'],\n",
    "    ]\n",
    "\n",
    "    for index, row in enumerate(asp_data_list[1:]):\n",
    "        sentence, predictions, corrects = row\n",
    "        for prediction in predictions:\n",
    "            transformed_asp_prediction_data_list.append([\n",
    "                index+1,\n",
    "                sentence,\n",
    "                prediction\n",
    "            ])\n",
    "\n",
    "    with open(asp_file_path+'test_asp_prediction_results.csv', mode=\"w\", newline=\"\", encoding=\"cp949\") as file:\n",
    "        writer = csv.writer(file)\n",
    "    \n",
    "        for row in transformed_asp_prediction_data_list:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    # Unnesting Correct\n",
    "    transformed_asp_correct_data_list = [\n",
    "        ['id', 'sentence', 'correct'],\n",
    "    ]\n",
    "\n",
    "    for index, row in enumerate(asp_data_list[1:]):\n",
    "        sentence, predictions, corrects = row\n",
    "        for correct in corrects:\n",
    "            transformed_asp_correct_data_list.append([\n",
    "                index+1,\n",
    "                sentence,\n",
    "                correct\n",
    "            ])\n",
    "\n",
    "    with open(asp_file_path+'test_asp_correct_results.csv', mode=\"w\", newline=\"\", encoding=\"cp949\") as file:\n",
    "        writer = csv.writer(file)\n",
    "    \n",
    "        for row in transformed_asp_correct_data_list:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    ### 감성(Sentiment) ###\n",
    "    sen_file_path = f'./NLP/{main_category}/test_sen_results.csv'\n",
    "\n",
    "    sen_data_list = [\n",
    "        ['sentence', 'prediction', 'correct'], # Column Title\n",
    "    ]\n",
    "\n",
    "    for i in range(0, len(test_SEN_data)):\n",
    "        sen_data_list.append([test_SEN_data[i], sen_infers[0][i], test_SEN_labels[i]])\n",
    "\n",
    "    with open(sen_file_path, mode=\"w\", newline=\"\", encoding=\"cp949\") as file:\n",
    "        writer = csv.writer(file)\n",
    "    \n",
    "        for row in sen_data_list:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0653dd62-1d79-4513-8820-72924a35b47a",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a05040-bfcd-4cc3-8bd9-914b909af4f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    check_exists_cuda(device)\n",
    "    \n",
    "    set_seed()\n",
    "    main_categories = [\n",
    "        '스킨케어',\n",
    "        '헤어_바디케어',\n",
    "        '메이크업_뷰티소품',\n",
    "        '남성화장품'\n",
    "    ]\n",
    "    \n",
    "    for main_category in main_categories:\n",
    "        print(f\"================={main_category}====================\")\n",
    "        trains, validations, tests, category_with_original_aspects = prepare_data_and_categories(main_category)\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        test_ASP_datas, test_ASP_labels, test_SEN_data, test_SEN_labels = define_datasets(tests, main_category, category_with_original_aspects)\n",
    "    \n",
    "        # 1차원 변환, aspect는 리스트 반환하고 sentiment는 단일 반환\n",
    "        test_aspect_klue_sets = reshape_to_1d('aspect', test_ASP_datas, test_ASP_labels, tokenizer)\n",
    "        test_sentiment_klue_sets = reshape_to_1d('sentiment', test_SEN_data, test_SEN_labels, tokenizer)\n",
    "\n",
    "        # Aspect model test\n",
    "        asp_infers, asp_infer_labels = aspect_evaluate_tests(device, main_category, test_aspect_klue_sets)\n",
    "        \n",
    "        # Aspect test scores 출력\n",
    "        show_test_evaluation('aspect', asp_infers, asp_infer_labels, category_with_original_aspects)\n",
    "        \n",
    "        # Sentiment model test\n",
    "        sen_infers, sen_infer_labels = sentiment_evaluate_tests(device, main_category, test_sentiment_klue_sets)\n",
    "           \n",
    "        # Sentiment test scores 출력\n",
    "        show_test_evaluation('sentiment', sen_infers, sen_infer_labels)\n",
    "        \n",
    "        print(\"================================================\")\n",
    "\n",
    "        # 테스트 결과 따로 저장\n",
    "        save_prediction_results(main_category, category_with_original_aspects \\\n",
    "                                , test_ASP_datas, test_ASP_labels, asp_infers \\\n",
    "                                , test_SEN_data, test_SEN_labels, sen_infers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
